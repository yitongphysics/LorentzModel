{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: number of beads; number of probes; box size\n",
    "\n",
    "# Output:\n",
    "# 1. Configuration: positions of obstacles (r=2) and probes (r=0)\n",
    "# 2. Obstacle: id, image id, tetrahedron id\n",
    "# 3. Tetrahedron: id, image id, if percolation, obstacles id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import Voronoi\n",
    "from scipy.spatial import Delaunay\n",
    "import networkx as nx\n",
    "import random\n",
    "import copy\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import imageio.v2 as imageio\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(\"error\")\n",
    "from types import MappingProxyType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "seedNumber = 0\n",
    "numBeads = 1000\n",
    "numProbes = 1000\n",
    "box_size = 100.0\n",
    "\n",
    "filepath =  str(numBeads) + '_' + str(seedNumber)\n",
    "\n",
    "np.random.seed(seedNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replicate_points(points, box_size):\n",
    "    \"\"\"Replicate points across periodic boundaries.\"\"\"\n",
    "    replicas = []\n",
    "    for dx in [-box_size, 0, box_size]:\n",
    "        for dy in [-box_size, 0, box_size]:\n",
    "            for dz in [-box_size, 0, box_size]:\n",
    "                if dx == dy == dz == 0:\n",
    "                    continue\n",
    "                shift = np.array([dx, dy, dz])\n",
    "                replicas.append(points + shift)\n",
    "    return np.vstack((points, *replicas))\n",
    "\n",
    "# generate random points in the box\n",
    "np.random.seed(42) # fix random seeds\n",
    "points = np.random.rand(numBeads, 3) * box_size  # Generate some random points\n",
    "\n",
    "# Replicate points to account for PBC\n",
    "points_PBC = replicate_points(points, box_size)\n",
    "\n",
    "# Compute the Voronoi tessellation and Delaunay tessellation\n",
    "tetra = Delaunay(points_PBC)\n",
    "vor = Voronoi(points_PBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexSimplex = defaultdict(set)\n",
    "for tid, simplex in enumerate(tetra.simplices):\n",
    "    for vid in simplex:\n",
    "        vertexSimplex[vid].add(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle_area(p, q, r):\n",
    "    return 0.5 * np.linalg.norm(np.cross(q - p, r - p))\n",
    "\n",
    "def tetrahedron_incenter(A, B, C, D):\n",
    "    # Areas of faces opposite each vertex\n",
    "    alpha_A = triangle_area(B, C, D)  # face BCD\n",
    "    alpha_B = triangle_area(A, C, D)  # face ACD\n",
    "    alpha_C = triangle_area(A, B, D)  # face ABD\n",
    "    alpha_D = triangle_area(A, B, C)  # face ABC\n",
    "\n",
    "    # Compute weighted sum of vertices\n",
    "    numerator = (alpha_A * A\n",
    "                 + alpha_B * B\n",
    "                 + alpha_C * C\n",
    "                 + alpha_D * D)\n",
    "    denominator = (alpha_A + alpha_B + alpha_C + alpha_D)\n",
    "\n",
    "    # Return the incenter\n",
    "    return numerator / denominator\n",
    "\n",
    "comAll = [] # array of COM\n",
    "for i in range(len(tetra.simplices)):\n",
    "    point = points_PBC[tetra.simplices[i]]\n",
    "    comAll.append(tetrahedron_incenter(point[0], point[1], point[2], point[3]))\n",
    "comAll = np.array(comAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "primaryStates = set()\n",
    "# if the COM of the tetra is inside the main box\n",
    "for i, simplex in enumerate(tetra.simplices):\n",
    "    com = comAll[i]\n",
    "    if np.max(com) < box_size and np.min(com) > 0:\n",
    "        primaryStates.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({27: 4699, 18: 1795, 12: 244, 8: 9, 17585: 1})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tetra index in the primary cell\n",
    "def findPrimaryTetra(i):\n",
    "    global tetra, primaryStates, numBeads, vertexSimplex, indexPrimary\n",
    "\n",
    "    # if it is already inside\n",
    "    if i in primaryStates:\n",
    "        return i\n",
    "    \n",
    "    vertices = copy.deepcopy(tetra.simplices[i])\n",
    "    for i in range(4):\n",
    "        while vertices[i] >= numBeads:\n",
    "            vertices[i] -= numBeads\n",
    "    if len(set(vertices)) < 4:\n",
    "        return -1\n",
    "    \n",
    "    for a in range(27):\n",
    "        set1 = vertexSimplex[vertices[0]]\n",
    "        for b in range(27):\n",
    "            set2 = set1 & vertexSimplex[vertices[1]]\n",
    "            if len(set2) > 0:\n",
    "                for c in range(27):\n",
    "                    set3 = set2 & vertexSimplex[vertices[2]]\n",
    "                    if len(set3) > 0:\n",
    "                        for d in range(27):\n",
    "                            setAll = set3 & vertexSimplex[vertices[3]]\n",
    "                            if len(setAll) > 0:\n",
    "                                candidate = setAll.pop()\n",
    "                                if candidate in indexPrimary:\n",
    "                                    return indexPrimary[candidate]\n",
    "                                if candidate in primaryStates:\n",
    "                                    return candidate\n",
    "\n",
    "                            vertices[3] += numBeads\n",
    "                    vertices[2] += numBeads\n",
    "                    vertices[3] %= numBeads\n",
    "            vertices[1] += numBeads\n",
    "            vertices[2] %= numBeads\n",
    "            vertices[3] %= numBeads\n",
    "        vertices[0] += numBeads\n",
    "        vertices[1] %= numBeads\n",
    "        vertices[2] %= numBeads\n",
    "        vertices[3] %= numBeads\n",
    "\n",
    "    return -1\n",
    "\n",
    "indexPrimary = dict()\n",
    "for i in range(len(tetra.simplices)):\n",
    "    indexPrimary[i] = findPrimaryTetra(i)\n",
    "\n",
    "Counter(Counter(indexPrimary.values()).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all nodes:  179734\n",
      "Number of nodes:  53972\n",
      "Number of edges:  103062\n"
     ]
    }
   ],
   "source": [
    "# construct graph and edge list\n",
    "def circumRadius(p1, p2, p3):\n",
    "    a = np.linalg.norm(p2 - p3)\n",
    "    b = np.linalg.norm(p1 - p3)\n",
    "    c = np.linalg.norm(p1 - p2)\n",
    "    \n",
    "    cross_product = np.cross(p2 - p1, p3 - p1)\n",
    "    area = np.linalg.norm(cross_product) / 2\n",
    "\n",
    "    return (a * b * c) / (4 * area)\n",
    "\n",
    "def point_to_segment_distance(P, A, B):\n",
    "    AB = B - A\n",
    "    normAB2 = np.dot(AB, AB)\n",
    "    if np.allclose(AB, 0):\n",
    "        distances = np.linalg.norm(P - A, axis=1)\n",
    "        return distances\n",
    "    \n",
    "    AP = P - A  # shape: (N, d)\n",
    "    t = np.dot(AP, AB) / normAB2  # shape: (N,)\n",
    "    t_clamped = np.clip(t, 0, 1)\n",
    "    closest_points = A + np.outer(t_clamped, AB)\n",
    "    return np.linalg.norm(P - closest_points, axis=1)\n",
    "\n",
    "def constructGraph(vor):\n",
    "    \"\"\"Filter edges based on distance to the nearest input point.\"\"\"\n",
    "    N = len(vor.vertices)\n",
    "    G = nx.Graph()\n",
    "    edgeList = []\n",
    "    visited = set()\n",
    "    for i, ridge in enumerate(vor.ridge_vertices): # loop over faces\n",
    "        for vertex_idx in range(len(ridge)-1):     # loop over vertices on face\n",
    "            v1, v2 = ridge[vertex_idx], ridge[vertex_idx + 1]\n",
    "            if v1 < 0 or v2 < 0 or (v1, v2) in visited or (v2, v1) in visited:\n",
    "                continue  # Skip if edge goes to infinity\n",
    "            visited.add((v1, v2))\n",
    "            point1 = vor.vertices[v1]\n",
    "            point2 = vor.vertices[v2]\n",
    "            if point1[0] < -box_size/2 or point1[1] < -box_size/2 or point1[2] < -box_size/2 or point1[0] > 1.5*box_size or point1[1] > 1.5*box_size or point1[2] > 1.5*box_size:\n",
    "                continue\n",
    "            if point2[0] < -box_size/2 or point2[1] < -box_size/2 or point2[2] < -box_size/2 or point2[0] > 1.5*box_size or point2[1] > 1.5*box_size or point2[2] > 1.5*box_size:\n",
    "                continue\n",
    "\n",
    "            dist = min(point_to_segment_distance(vor.points, point1, point2))\n",
    "            G.add_edge(v1, v2)\n",
    "            edgeList.append([v1, v2, dist])\n",
    "\n",
    "    print(\"Number of all nodes: \", N)\n",
    "    print(\"Number of nodes: \", len(G.nodes()))\n",
    "    print(\"Number of edges: \", len(edgeList))\n",
    "    return G, edgeList\n",
    "\n",
    "fullGraph, edgeList = constructGraph(vor)\n",
    "edgeList.sort(key = lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifPercolate(component, box_size, vor):\n",
    "    largestVoidVertices = vor.vertices[np.array(list(component[0]))]\n",
    "    visited = set()\n",
    "    for i, vi in enumerate(largestVoidVertices):\n",
    "        dists = np.linalg.norm(vor.points - vi, axis=1)\n",
    "        closest_idx = np.argpartition(dists, 4)[:4]\n",
    "        closest_idx = closest_idx[np.argsort(dists[closest_idx])] % numBeads\n",
    "        closePoints = tuple(closest_idx)\n",
    "        if closePoints in visited:\n",
    "            return True\n",
    "        else:\n",
    "            visited.add(closePoints)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77296 9.181365355832503\n",
      "90179 10.067674591586108\n",
      "83737 9.586139242592399\n",
      "80516 9.388578455480388\n",
      "78906 9.282399617890334\n",
      "78101 9.235844619212088\n",
      "77698 9.199469905578134\n",
      "77497 9.19171431113398\n",
      "77597 9.195242088792218\n",
      "77647 9.197034584653899\n",
      "77622 9.196449542368965\n",
      "77609 9.195481806050077\n",
      "77615 9.196438094639507\n",
      "77612 9.19548180605008\n",
      "77613 9.19548180605008\n"
     ]
    }
   ],
   "source": [
    "l = len(edgeList)//2\n",
    "r = len(edgeList)\n",
    "m = 0\n",
    "while r-l>1:\n",
    "    G = copy.deepcopy(fullGraph)\n",
    "    m = (l+r) // 2\n",
    "    for i in range(m):\n",
    "        G.remove_edge(edgeList[i][0], edgeList[i][1])\n",
    "    print(m, edgeList[m][2])\n",
    "    connected_components = list(nx.connected_components(G))\n",
    "    connected_components = [[component,len(component)] for component in connected_components]\n",
    "    connected_components.sort(key = lambda x:x[1], reverse=True)\n",
    "    ifPerco = False\n",
    "    for component in connected_components[:5]:\n",
    "        if ifPercolate(component,box_size, vor):\n",
    "            ifPerco = True\n",
    "            break\n",
    "    if len(connected_components) != 0 and ifPerco:\n",
    "        l = m\n",
    "    else:\n",
    "        r = m\n",
    "mPerco = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.19548180605008 False 1411\n"
     ]
    }
   ],
   "source": [
    "rPerco = edgeList[m][2]\n",
    "r_cut = rPerco\n",
    "G = copy.deepcopy(fullGraph)\n",
    "for i in range(len(edgeList)):\n",
    "    if edgeList[i][2] > r_cut:\n",
    "        break\n",
    "    G.remove_edge(edgeList[i][0], edgeList[i][1])\n",
    "\n",
    "connected_components = list(nx.connected_components(G))\n",
    "connected_components = [[component,len(component)] for component in connected_components]\n",
    "connected_components.sort(key = lambda x:x[1], reverse=True)\n",
    "ifPerco = False\n",
    "for component in connected_components[:5]:\n",
    "    if ifPercolate(component, box_size, vor):\n",
    "        ifPerco = True\n",
    "        break\n",
    "if not ifPerco:\n",
    "    component = connected_components[0]\n",
    "\n",
    "print(r_cut, ifPercolate(component, box_size, vor), len(list(component[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Markov Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of primary states =  830\n"
     ]
    }
   ],
   "source": [
    "subG = G.subgraph(component[0])\n",
    "vertices = vor.vertices[list(component[0])]\n",
    "states = set()\n",
    "\n",
    "def segment_intersects_triangle(ABC, P, Q): # if a line segment pass through a triangle\n",
    "    A, B, C = ABC[0], ABC[1], ABC[2]\n",
    "    N = np.cross(B - A, C - A)\n",
    "    norm_N = np.linalg.norm(N)\n",
    "    d = Q - P\n",
    "    denom = np.dot(d, N)\n",
    "    t = -np.dot(P - A, N) / denom\n",
    "    if t < 0 or t > 1:\n",
    "        # Intersection point is not on the line segment.\n",
    "        return False\n",
    "    \n",
    "    # barycentric coordinates: check if Intersection point is inside triangle\n",
    "    X = P + t * d\n",
    "    v0 = C - A\n",
    "    v1 = B - A\n",
    "    v2 = X - A\n",
    "    dot00 = np.dot(v0, v0)\n",
    "    dot01 = np.dot(v0, v1)\n",
    "    dot02 = np.dot(v0, v2)\n",
    "    dot11 = np.dot(v1, v1)\n",
    "    dot12 = np.dot(v1, v2)\n",
    "    invDenom = 1.0 / (dot00 * dot11 - dot01 * dot01)\n",
    "    u = (dot11 * dot02 - dot01 * dot12) * invDenom\n",
    "    v = (dot00 * dot12 - dot01 * dot02) * invDenom\n",
    "    if u >= 0 and v >= 0 and (u + v) <= 1.0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bisectionSearch(p1, p2):\n",
    "    global edge\n",
    "\n",
    "    tetra1 = int(tetra.find_simplex(p1))\n",
    "    tetra2 = int(tetra.find_simplex(p2))\n",
    "    states.add(tetra1)\n",
    "    states.add(tetra2)\n",
    "\n",
    "    if tetra1 == tetra2:\n",
    "        return\n",
    "    \n",
    "    # deal with werid case\n",
    "    # 1. edges from VT may pass through some tetrahedron. So the two ends of the edge are not in neighboring tetrahedrons.\n",
    "    # 2. edges from VT may pass through other tetrahedron and then end up in the neighboring tetrahedron.\n",
    "    commonVertices = set(tetra.simplices[tetra1]) & set(tetra.simplices[tetra2])\n",
    "    if len(commonVertices) < 3 or not segment_intersects_triangle(points_PBC[list(commonVertices)], p1, p2):\n",
    "        midPoint = (p1 + p2) / 2\n",
    "        bisectionSearch(p1, midPoint)\n",
    "        bisectionSearch(midPoint, p2)\n",
    "\n",
    "for edge in list(subG.edges):\n",
    "    bisectionSearch(vor.vertices[edge[0]], vor.vertices[edge[1]])\n",
    "    t1 = int(tetra.find_simplex(vor.vertices[edge[0]]))\n",
    "    t2 = int(tetra.find_simplex(vor.vertices[edge[1]]))\n",
    "        \n",
    "states = list(states)\n",
    "states.sort()\n",
    "\n",
    "statePrimary = set() # id of the primary states\n",
    "for i in states:\n",
    "    statePrimary.add(indexPrimary[i])\n",
    "if -1 in statePrimary:\n",
    "    statePrimary.remove(-1)\n",
    "    \n",
    "statePrimary = list(statePrimary) # statePrimary[new id] = original id\n",
    "statePrimary.sort()\n",
    "nStates = len(statePrimary)\n",
    "print(\"Number of primary states = \",nStates)\n",
    "\n",
    "statePrimaryInverse = {value: key for key, value in enumerate(statePrimary)} # statePrimaryInverse[original id] = new id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute volume of tetra\n",
    "def sample_point_in_tetrahedron(vertices):\n",
    "    rn = -np.log(np.random.rand(4))\n",
    "    return np.dot(rn / np.sum(rn), vertices)\n",
    "\n",
    "nTrails = 10_000\n",
    "def cavityVolume(vertices, r):\n",
    "    global nTrials\n",
    "    V0 = abs(np.dot(vertices[1]-vertices[0], np.cross(vertices[2]-vertices[0], vertices[3]-vertices[0]))) / 6.0\n",
    "\n",
    "    cnt = 0\n",
    "    for _  in range(nTrails):\n",
    "        pt = sample_point_in_tetrahedron(vertices)\n",
    "        for i in range(4):\n",
    "            if np.linalg.norm(pt - vertices[i]) < r:\n",
    "                cnt += 1\n",
    "                break\n",
    "    if cnt == nTrails:\n",
    "        cnt -= 1\n",
    "    return V0 * (nTrails - cnt) / nTrails\n",
    "\n",
    "\n",
    "idVol = np.zeros(nStates)\n",
    "for cnt, i in enumerate(statePrimary):\n",
    "    idVol[cnt] = cavityVolume(points_PBC[tetra.simplices[i]], r_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_bisector_intersection(A, B, C):\n",
    "    \"\"\"\n",
    "    AB cross AC bisector at X, make sure AB is the longest side\n",
    "    return X and AX distance\n",
    "    \"\"\"\n",
    "    AB = B - A\n",
    "    AC = C - A\n",
    "    \n",
    "    # Parameter t along AB for the intersection:\n",
    "    t = np.linalg.norm(AC)**2 / (2 * np.dot(AC, AB))\n",
    "    #print(np.linalg.norm(AB), np.linalg.norm(AC), np.linalg.norm(B-C))\n",
    "    \n",
    "    # Intersection point:\n",
    "    X = A + t * AB\n",
    "    # Distance from A to X:\n",
    "    d = np.linalg.norm(X - A)\n",
    "    return d, X\n",
    "\n",
    "def sphere_line_intersection_closer_to_B(A, B, C, r):\n",
    "    d = B - A\n",
    "    V = A - C\n",
    "    d_norm_sq = np.dot(d, d)\n",
    "    \n",
    "    discriminant = (np.dot(V, d))**2 - d_norm_sq*(np.dot(V, V) - r**2)\n",
    "    sqrt_disc = np.sqrt(discriminant)\n",
    "    t = (-np.dot(V, d) + sqrt_disc) / d_norm_sq\n",
    "    \n",
    "    X = A + t * d\n",
    "    distance = np.linalg.norm(X - A)\n",
    "    \n",
    "    return X, distance\n",
    "\n",
    "def computeExitArea(p1, p2, p3, r):\n",
    "    c = np.linalg.norm(p1-p2)\n",
    "    b = np.linalg.norm(p1-p3)\n",
    "    a = np.linalg.norm(p3-p2)\n",
    "\n",
    "    # make sure c is the longest\n",
    "    if a > b and a > c:\n",
    "        a, c = copy.deepcopy(c), copy.deepcopy(a)\n",
    "        p1, p3 = copy.deepcopy(p3), copy.deepcopy(p1)\n",
    "    if b > a and b > c:\n",
    "        b, c = copy.deepcopy(c), copy.deepcopy(b)\n",
    "        p2, p3 = copy.deepcopy(p3), copy.deepcopy(p2)\n",
    "    s = (a + b + c) / 2\n",
    "    areaTriangle = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    R = a*b*c/4/areaTriangle\n",
    "    if R <= r:\n",
    "        return 0\n",
    "    \n",
    "    # if obtuse triangle and two circles intersect outside the triangle\n",
    "    d_AC, X_AC = distance_to_bisector_intersection(p1, p2, p3)\n",
    "    d_BC, X_BC = distance_to_bisector_intersection(p2, p1, p3)\n",
    "    #print(d_AC, d_BC, r)\n",
    "    if r > d_AC and r > d_BC:\n",
    "        return 0.0\n",
    "    if r > d_AC or r > d_BC:\n",
    "        if d_BC < d_AC: # make sure the side close to A is covered instead of B.\n",
    "            a, b = b, a\n",
    "            p1, p2 = p2, p1\n",
    "            d_AC, d_BC = d_BC, d_AC\n",
    "            X_AC, X_BC = X_BC, X_AC\n",
    "            X, XA = sphere_line_intersection_closer_to_B(p1, p2, p3, r)\n",
    "            b = r\n",
    "            c = c - XA\n",
    "            s = (a + b + c) / 2\n",
    "            areaTriangle = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "            angleX = np.arccos(np.clip(np.dot(p3-X, p2-X) / b / c, -1, 1))\n",
    "            areaTriangle -= r*r/2 * (np.pi - angleX)\n",
    "            if a < 2*r:\n",
    "                areaTriangle += r*r*np.arccos(a / (2 * r)) - (a / 4) * np.sqrt(4 * r**2 - a**2)\n",
    "            return areaTriangle\n",
    "\n",
    "    dA = areaTriangle * 2.0 / a\n",
    "    dB = areaTriangle * 2.0 / b\n",
    "    dC = areaTriangle * 2.0 / c\n",
    "    areaTriangle -= np.pi * r * r / 2\n",
    "    # deal with overlaps\n",
    "    if a < 2*r:\n",
    "        areaTriangle += r*r*np.arccos(a / (2 * r)) - (a / 4) * np.sqrt(4 * r**2 - a**2)\n",
    "    if b < 2*r:\n",
    "        areaTriangle += r*r*np.arccos(b / (2 * r)) - (b / 4) * np.sqrt(4 * r**2 - b**2)\n",
    "    if c < 2*r:\n",
    "        areaTriangle += r*r*np.arccos(c / (2 * r)) - (c / 4) * np.sqrt(4 * r**2 - c**2)\n",
    "    # deal with truncation from the opsite side\n",
    "    if dA < r:\n",
    "        areaTriangle += r**2 * np.arccos(dA/r) - dA * np.sqrt(r**2 - dA**2)\n",
    "    if dB < r:\n",
    "        areaTriangle += r**2 * np.arccos(dB/r) - dB * np.sqrt(r**2 - dB**2)\n",
    "    if dC < r:\n",
    "        areaTriangle += r**2 * np.arccos(dC/r) - dC * np.sqrt(r**2 - dC**2)\n",
    "\n",
    "    return areaTriangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States not accessible:  []\n",
      "States not accessible:  []\n"
     ]
    }
   ],
   "source": [
    "def periodicSearch(com, comDict, box_size):\n",
    "    for dx in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            for dz in [-1, 0, 1]:\n",
    "                comTmp = (com[0] + dx*box_size, com[1] + dy*box_size, com[2] + dz*box_size)\n",
    "                if comTmp in comDict:\n",
    "                    return comDict[comTmp]\n",
    "    return -1\n",
    "\n",
    "transitionPrimary = set()\n",
    "G = nx.DiGraph()\n",
    "for i in statePrimary:\n",
    "    neighborTmp = []\n",
    "    for neighbor in tetra.neighbors[i]:\n",
    "        if indexPrimary[neighbor] in statePrimary:\n",
    "            neighborVertices = points_PBC[tetra.simplices[neighbor]]\n",
    "            vCommon = list(set(tetra.simplices[i]) & set(tetra.simplices[neighbor]))\n",
    "            exitArea = computeExitArea(points_PBC[vCommon[0]], points_PBC[vCommon[1]], points_PBC[vCommon[2]], r_cut)\n",
    "            if exitArea > 0.0:\n",
    "                transitionPrimary.add(i)\n",
    "                transitionPrimary.add(indexPrimary[neighbor])\n",
    "                neighborTmp.append(indexPrimary[neighbor])\n",
    "                G.add_edge(i, indexPrimary[neighbor])\n",
    "            \n",
    "print(\"States not accessible: \", sorted(list((set(statePrimary) - transitionPrimary))))\n",
    "print(\"States not accessible: \", sorted(list((transitionPrimary - set(statePrimary)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unidirectional edges: []\n"
     ]
    }
   ],
   "source": [
    "# test unidirectional edge\n",
    "unidir_edges = [(u, v) for u, v in G.edges() if not G.has_edge(v, u)]\n",
    "print(\"Unidirectional edges:\", unidir_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sccs = list(nx.weakly_connected_components(G))\n",
    "sccs = sorted(sccs, key=len, reverse = True)\n",
    "sccs = [list(comp) for comp in sccs]\n",
    "len(sccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_id = [i for i in range(numBeads * 27)]\n",
    "points_image_id = [i%numBeads for i in range(numBeads * 27)]\n",
    "points_PBC_df = pd.DataFrame({'id': points_id, 'image_id': points_image_id})\n",
    "\n",
    "points_PBC_df['tetra_id'] = [[] for _ in range(len(points_PBC_df))]\n",
    "for tid, simplex in enumerate(tetra.simplices):\n",
    "    for vid in simplex:\n",
    "        points_PBC_df.loc[vid, 'tetra_id'].append(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tetra_id = [i for i in range(len(tetra.simplices))]\n",
    "tetra_obstacles_id = [sorted(i) for i in tetra.simplices]\n",
    "\n",
    "tetra_df = pd.DataFrame({'id': tetra_id, 'obstacles_id': tetra_obstacles_id})\n",
    "\n",
    "\n",
    "tetra_df['x'] = comAll[:,0]\n",
    "tetra_df['y'] = comAll[:,1]\n",
    "tetra_df['z'] = comAll[:,2]\n",
    "\n",
    "tetra_df['is_prime'] = (tetra_df['x'] > 0) & (tetra_df['x'] < box_size) & (tetra_df['y'] > 0) & (tetra_df['y'] < box_size) & (tetra_df['z'] > 0) & (tetra_df['z'] < box_size)\n",
    "tetra_df['image_id'] = tetra_df['id'].apply(lambda x: indexPrimary[x])\n",
    "\n",
    "tetra_df['is_percolation'] = tetra_df['id'].apply(lambda x: x in statePrimary)\n",
    "tetra_df['percolation_id'] = tetra_df['is_percolation'].cumsum()\n",
    "tetra_df.loc[~tetra_df['is_percolation'], 'percolation_id'] = -1\n",
    "tetra_df.loc[tetra_df['is_percolation'], 'percolation_id'] = tetra_df.loc[tetra_df['is_percolation'], 'percolation_id']-1\n",
    "tetra_df.loc[tetra_df['is_percolation'], 'volume'] = tetra_df.loc[tetra_df['is_percolation'], 'percolation_id'].apply(lambda x: idVol[x])\n",
    "tetra_df['vol_fraction'] = tetra_df['volume'] / sum(idVol)\n",
    "tetra_df['vol_fraction'] = tetra_df['vol_fraction'].fillna(0)\n",
    "tetra_df['vol_fraction_cum'] = tetra_df['vol_fraction'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate probe particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tetra_df['num_probes'] = tetra_df['vol_fraction'].apply(lambda x: int(x*numProbes)+1)\n",
    "tetra_df.loc[~tetra_df['is_percolation'], 'num_probes'] = 0\n",
    "\n",
    "probes_XYZ = []\n",
    "for i, row in tetra_df[tetra_df['is_percolation']].iterrows():\n",
    "    print(i, row['volume'])\n",
    "    vertices = np.array([points_PBC[i] for i in row['obstacles_id']])\n",
    "\n",
    "    cnt = 0\n",
    "    for _ in range(row['num_probes']):\n",
    "        ifOverlap = True\n",
    "        while ifOverlap:\n",
    "            cnt += 1\n",
    "            if cnt > int(1e4):\n",
    "                break\n",
    "            ifOverlap = False\n",
    "            probeTmp = sample_point_in_tetrahedron(vertices)\n",
    "            \n",
    "            for obstacle in points_PBC:\n",
    "                if np.linalg.norm(probeTmp - obstacle) <= r_cut:\n",
    "                    ifOverlap = True\n",
    "                    break\n",
    "                \n",
    "        if not ifOverlap:\n",
    "            probes_XYZ.append(probeTmp)\n",
    "probes_XYZ = np.array(probes_XYZ)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m probeTmp \u001b[38;5;241m=\u001b[39m sample_point_in_tetrahedron(vertices)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obstacle \u001b[38;5;129;01min\u001b[39;00m points_PBC:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobeTmp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobstacle\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r_cut:\n\u001b[1;32m     14\u001b[0m         ifOverlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/linalg/linalg.py:2379\u001b[0m, in \u001b[0;36m_norm_dispatcher\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2375\u001b[0m     result \u001b[38;5;241m=\u001b[39m op(svd(y, compute_uv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 2379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_norm_dispatcher\u001b[39m(x, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (x,)\n\u001b[1;32m   2383\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_norm_dispatcher)\n\u001b[1;32m   2384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnorm\u001b[39m(x, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "probes_XYZ = []\n",
    "for _ in range(numProbes):\n",
    "    ifOverlap = True\n",
    "    while ifOverlap:\n",
    "        ifOverlap = False\n",
    "        \n",
    "        rd = np.random.random()\n",
    "        ind = tetra_df.loc[tetra_df['vol_fraction_cum']>rd].iloc[0]['id']\n",
    "        vertices = np.array([points_PBC[i] for i in tetra_df.loc[ind, 'obstacles_id']])\n",
    "        probeTmp = sample_point_in_tetrahedron(vertices)\n",
    "        \n",
    "        for obstacle in points_PBC:\n",
    "            if np.linalg.norm(probeTmp - obstacle) <= r_cut:\n",
    "                ifOverlap = True\n",
    "                break\n",
    "\n",
    "    probes_XYZ.append(probeTmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthUnit = r_cut*0.5\n",
    "\n",
    "tetra_df['x'] = tetra_df['x']/lengthUnit\n",
    "tetra_df['y'] = tetra_df['y']/lengthUnit\n",
    "tetra_df['z'] = tetra_df['z']/lengthUnit\n",
    "\n",
    "tetra_df['volume'] = tetra_df['volume']/lengthUnit**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# save configurations\n",
    "outfile = filepath + '.pos'\n",
    "with open(outfile, 'w') as output_fileID:\n",
    "    output_fileID.write(f'{len(points) + len(probes_XYZ)}\\n')\n",
    "    output_fileID.write(f'Lattice=\"{box_size/lengthUnit} 0 0 0 {box_size/lengthUnit} 0 0 0 {box_size/lengthUnit}\" Properties=species:S:1:pos:R:3:radius:R:1\\n')\n",
    "\n",
    "    for bid in range(len(points)):\n",
    "        output_fileID.write(f'{0} {points[bid][0]/lengthUnit} {points[bid][1]/lengthUnit} {points[bid][2]/lengthUnit} {2.0}\\n')\n",
    "    for probe in probes_XYZ:\n",
    "        output_fileID.write(f'{1} {probe[0]/lengthUnit} {probe[1]/lengthUnit} {probe[2]/lengthUnit} {0.0}\\n')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save obstacles info\n",
    "outfile = filepath + '_obstacles.csv'\n",
    "#points_PBC_df.to_csv(outfile, index = False, float_format='%.17f')\n",
    "\n",
    "outfile = filepath + '_tetra.txt'\n",
    "\n",
    "tetra_df[tetra_df['is_prime']].to_csv(outfile, sep=',', index = False, float_format='%.18f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
