{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: number of beads; number of probes; box size\n",
    "\n",
    "# Output:\n",
    "# 1. Configuration: positions of obstacles (r=2) and probes (r=0)\n",
    "# 2. Obstacle: id, image id, tetrahedron id\n",
    "# 3. Tetrahedron: id, image id, if percolation, obstacles id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import Voronoi\n",
    "from scipy.spatial import Delaunay\n",
    "import networkx as nx\n",
    "import random\n",
    "import copy\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(\"error\")\n",
    "from types import MappingProxyType\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "seedNumber = 0\n",
    "numBeads = 1000\n",
    "numProbes = 10000\n",
    "box_size = 100.0\n",
    "\n",
    "filepath =  str(numBeads) + '_' + str(seedNumber)\n",
    "\n",
    "np.random.seed(seedNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replicate_points(points, box_size):\n",
    "    \"\"\"Replicate points across periodic boundaries.\"\"\"\n",
    "    replicas = []\n",
    "    for dx in [-box_size, 0, box_size]:\n",
    "        for dy in [-box_size, 0, box_size]:\n",
    "            for dz in [-box_size, 0, box_size]:\n",
    "                if dx == dy == dz == 0:\n",
    "                    continue\n",
    "                shift = np.array([dx, dy, dz])\n",
    "                replicas.append(points + shift)\n",
    "    return np.vstack((points, *replicas))\n",
    "\n",
    "# generate random points in the box\n",
    "np.random.seed(42) # fix random seeds\n",
    "points = np.random.rand(numBeads, 3) * box_size  # Generate some random points\n",
    "\n",
    "# Replicate points to account for PBC\n",
    "points_PBC = replicate_points(points, box_size)\n",
    "\n",
    "# Compute the Voronoi tessellation and Delaunay tessellation\n",
    "tetra = Delaunay(points_PBC)\n",
    "vor = Voronoi(points_PBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexSimplex = defaultdict(set)\n",
    "for tid, simplex in enumerate(tetra.simplices):\n",
    "    for vid in simplex:\n",
    "        vertexSimplex[vid].add(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle_area(p, q, r):\n",
    "    return 0.5 * np.linalg.norm(np.cross(q - p, r - p))\n",
    "\n",
    "def tetrahedron_incenter(A, B, C, D):\n",
    "    # Areas of faces opposite each vertex\n",
    "    alpha_A = triangle_area(B, C, D)  # face BCD\n",
    "    alpha_B = triangle_area(A, C, D)  # face ACD\n",
    "    alpha_C = triangle_area(A, B, D)  # face ABD\n",
    "    alpha_D = triangle_area(A, B, C)  # face ABC\n",
    "\n",
    "    # Compute weighted sum of vertices\n",
    "    numerator = (alpha_A * A\n",
    "                 + alpha_B * B\n",
    "                 + alpha_C * C\n",
    "                 + alpha_D * D)\n",
    "    denominator = (alpha_A + alpha_B + alpha_C + alpha_D)\n",
    "\n",
    "    # Return the incenter\n",
    "    return numerator / denominator\n",
    "\n",
    "comAll = [] # array of COM\n",
    "for i in range(len(tetra.simplices)):\n",
    "    point = points_PBC[tetra.simplices[i]]\n",
    "    comAll.append(tetrahedron_incenter(point[0], point[1], point[2], point[3]))\n",
    "comAll = np.array(comAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "primaryStates = set()\n",
    "# if the COM of the tetra is inside the main box\n",
    "for i, simplex in enumerate(tetra.simplices):\n",
    "    com = comAll[i]\n",
    "    if np.max(com) < box_size and np.min(com) > 0:\n",
    "        primaryStates.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({27: 4699, 18: 1795, 12: 244, 8: 9, 17585: 1})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tetra index in the primary cell\n",
    "def findPrimaryTetra(i):\n",
    "    global tetra, primaryStates, numBeads, vertexSimplex, indexPrimary\n",
    "\n",
    "    # if it is already inside\n",
    "    if i in primaryStates:\n",
    "        return i\n",
    "    \n",
    "    vertices = copy.deepcopy(tetra.simplices[i])\n",
    "    for i in range(4):\n",
    "        while vertices[i] >= numBeads:\n",
    "            vertices[i] -= numBeads\n",
    "    if len(set(vertices)) < 4:\n",
    "        return -1\n",
    "    \n",
    "    for a in range(27):\n",
    "        set1 = vertexSimplex[vertices[0]]\n",
    "        for b in range(27):\n",
    "            set2 = set1 & vertexSimplex[vertices[1]]\n",
    "            if len(set2) > 0:\n",
    "                for c in range(27):\n",
    "                    set3 = set2 & vertexSimplex[vertices[2]]\n",
    "                    if len(set3) > 0:\n",
    "                        for d in range(27):\n",
    "                            setAll = set3 & vertexSimplex[vertices[3]]\n",
    "                            if len(setAll) > 0:\n",
    "                                candidate = setAll.pop()\n",
    "                                if candidate in indexPrimary:\n",
    "                                    return indexPrimary[candidate]\n",
    "                                if candidate in primaryStates:\n",
    "                                    return candidate\n",
    "\n",
    "                            vertices[3] += numBeads\n",
    "                    vertices[2] += numBeads\n",
    "                    vertices[3] %= numBeads\n",
    "            vertices[1] += numBeads\n",
    "            vertices[2] %= numBeads\n",
    "            vertices[3] %= numBeads\n",
    "        vertices[0] += numBeads\n",
    "        vertices[1] %= numBeads\n",
    "        vertices[2] %= numBeads\n",
    "        vertices[3] %= numBeads\n",
    "\n",
    "    return -1\n",
    "\n",
    "indexPrimary = dict()\n",
    "for i in range(len(tetra.simplices)):\n",
    "    indexPrimary[i] = findPrimaryTetra(i)\n",
    "\n",
    "Counter(Counter(indexPrimary.values()).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all nodes:  179734\n",
      "Number of nodes:  53972\n",
      "Number of edges:  103062\n"
     ]
    }
   ],
   "source": [
    "# construct graph and edge list\n",
    "def point_to_segment_distance(P, A, B):\n",
    "    AB = B - A\n",
    "    normAB2 = np.dot(AB, AB)\n",
    "    if np.allclose(AB, 0):\n",
    "        distances = np.linalg.norm(P - A, axis=1)\n",
    "        return distances\n",
    "    \n",
    "    AP = P - A  # shape: (N, d)\n",
    "    t = np.dot(AP, AB) / normAB2  # shape: (N,)\n",
    "    t_clamped = np.clip(t, 0, 1)\n",
    "    closest_points = A + np.outer(t_clamped, AB)\n",
    "    return np.linalg.norm(P - closest_points, axis=1)\n",
    "\n",
    "def constructGraph(vor):\n",
    "    \"\"\"Filter edges based on distance to the nearest input point.\"\"\"\n",
    "    N = len(vor.vertices)\n",
    "    G = nx.Graph()\n",
    "    edgeList = []\n",
    "    visited = set()\n",
    "    for i, ridge in enumerate(vor.ridge_vertices): # loop over faces\n",
    "        for vertex_idx in range(len(ridge)-1):     # loop over vertices on face\n",
    "            v1, v2 = ridge[vertex_idx], ridge[vertex_idx + 1]\n",
    "            if v1 < 0 or v2 < 0 or (v1, v2) in visited or (v2, v1) in visited:\n",
    "                continue  # Skip if edge goes to infinity\n",
    "            visited.add((v1, v2))\n",
    "            point1 = vor.vertices[v1]\n",
    "            point2 = vor.vertices[v2]\n",
    "            if point1[0] < -box_size/2 or point1[1] < -box_size/2 or point1[2] < -box_size/2 or point1[0] > 1.5*box_size or point1[1] > 1.5*box_size or point1[2] > 1.5*box_size:\n",
    "                continue\n",
    "            if point2[0] < -box_size/2 or point2[1] < -box_size/2 or point2[2] < -box_size/2 or point2[0] > 1.5*box_size or point2[1] > 1.5*box_size or point2[2] > 1.5*box_size:\n",
    "                continue\n",
    "\n",
    "            dist = min(point_to_segment_distance(vor.points, point1, point2))\n",
    "            G.add_edge(v1, v2)\n",
    "            edgeList.append([v1, v2, dist])\n",
    "\n",
    "    print(\"Number of all nodes: \", N)\n",
    "    print(\"Number of nodes: \", len(G.nodes()))\n",
    "    print(\"Number of edges: \", len(edgeList))\n",
    "    return G, edgeList\n",
    "\n",
    "fullGraph, edgeList = constructGraph(vor)\n",
    "edgeList.sort(key = lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifPercolate(component, box_size, vor):\n",
    "    largestVoidVertices = vor.vertices[np.array(list(component[0]))]\n",
    "    visited = set()\n",
    "    for i, vi in enumerate(largestVoidVertices):\n",
    "        dists = np.linalg.norm(vor.points - vi, axis=1)\n",
    "        closest_idx = np.argpartition(dists, 4)[:4]\n",
    "        closest_idx = closest_idx[np.argsort(dists[closest_idx])] % numBeads\n",
    "        closePoints = tuple(closest_idx)\n",
    "        if closePoints in visited:\n",
    "            return True\n",
    "        else:\n",
    "            visited.add(closePoints)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77296 9.181365355832503\n",
      "90179 10.067674591586108\n",
      "83737 9.586139242592399\n",
      "80516 9.388578455480388\n",
      "78906 9.282399617890334\n",
      "78101 9.235844619212088\n",
      "77698 9.199469905578134\n",
      "77497 9.19171431113398\n",
      "77597 9.195242088792218\n",
      "77647 9.197034584653899\n",
      "77622 9.196449542368965\n",
      "77609 9.195481806050077\n",
      "77615 9.196438094639507\n",
      "77612 9.19548180605008\n",
      "77613 9.19548180605008\n"
     ]
    }
   ],
   "source": [
    "l = len(edgeList)//2\n",
    "r = len(edgeList)\n",
    "m = 0\n",
    "while r-l>1:\n",
    "    G = copy.deepcopy(fullGraph)\n",
    "    m = (l+r) // 2\n",
    "    for i in range(m):\n",
    "        G.remove_edge(edgeList[i][0], edgeList[i][1])\n",
    "    print(m, edgeList[m][2])\n",
    "    connected_components = list(nx.connected_components(G))\n",
    "    connected_components = [[component,len(component)] for component in connected_components]\n",
    "    connected_components.sort(key = lambda x:x[1], reverse=True)\n",
    "    ifPerco = False\n",
    "    for component in connected_components[:5]:\n",
    "        if ifPercolate(component,box_size, vor):\n",
    "            ifPerco = True\n",
    "            break\n",
    "    if len(connected_components) != 0 and ifPerco:\n",
    "        l = m\n",
    "    else:\n",
    "        r = m\n",
    "mPerco = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.19548180605008 False 1411\n"
     ]
    }
   ],
   "source": [
    "rPerco = edgeList[m][2]\n",
    "r_cut = rPerco\n",
    "G = copy.deepcopy(fullGraph)\n",
    "for i in range(len(edgeList)):\n",
    "    if edgeList[i][2] > r_cut:\n",
    "        break\n",
    "    G.remove_edge(edgeList[i][0], edgeList[i][1])\n",
    "\n",
    "connected_components = list(nx.connected_components(G))\n",
    "connected_components = [[component,len(component)] for component in connected_components]\n",
    "connected_components.sort(key = lambda x:x[1], reverse=True)\n",
    "ifPerco = False\n",
    "for component in connected_components[:5]:\n",
    "    if ifPercolate(component, box_size, vor):\n",
    "        ifPerco = True\n",
    "        break\n",
    "if not ifPerco:\n",
    "    component = connected_components[0]\n",
    "\n",
    "print(r_cut, ifPercolate(component, box_size, vor), len(list(component[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Markov Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of primary states =  830\n"
     ]
    }
   ],
   "source": [
    "subG = G.subgraph(component[0])\n",
    "vertices = vor.vertices[list(component[0])]\n",
    "states = set()\n",
    "\n",
    "def segment_intersects_triangle(ABC, P, Q): # if a line segment pass through a triangle\n",
    "    A, B, C = ABC[0], ABC[1], ABC[2]\n",
    "    N = np.cross(B - A, C - A)\n",
    "    norm_N = np.linalg.norm(N)\n",
    "    d = Q - P\n",
    "    denom = np.dot(d, N)\n",
    "    t = -np.dot(P - A, N) / denom\n",
    "    if t < 0 or t > 1:\n",
    "        # Intersection point is not on the line segment.\n",
    "        return False\n",
    "    \n",
    "    # barycentric coordinates: check if Intersection point is inside triangle\n",
    "    X = P + t * d\n",
    "    v0 = C - A\n",
    "    v1 = B - A\n",
    "    v2 = X - A\n",
    "    dot00 = np.dot(v0, v0)\n",
    "    dot01 = np.dot(v0, v1)\n",
    "    dot02 = np.dot(v0, v2)\n",
    "    dot11 = np.dot(v1, v1)\n",
    "    dot12 = np.dot(v1, v2)\n",
    "    invDenom = 1.0 / (dot00 * dot11 - dot01 * dot01)\n",
    "    u = (dot11 * dot02 - dot01 * dot12) * invDenom\n",
    "    v = (dot00 * dot12 - dot01 * dot02) * invDenom\n",
    "    if u >= 0 and v >= 0 and (u + v) <= 1.0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bisectionSearch(p1, p2):\n",
    "    global edge\n",
    "\n",
    "    tetra1 = int(tetra.find_simplex(p1))\n",
    "    tetra2 = int(tetra.find_simplex(p2))\n",
    "    states.add(tetra1)\n",
    "    states.add(tetra2)\n",
    "\n",
    "    if tetra1 == tetra2:\n",
    "        return\n",
    "    \n",
    "    # deal with werid case\n",
    "    # 1. edges from VT may pass through some tetrahedron. So the two ends of the edge are not in neighboring tetrahedrons.\n",
    "    # 2. edges from VT may pass through other tetrahedron and then end up in the neighboring tetrahedron.\n",
    "    commonVertices = set(tetra.simplices[tetra1]) & set(tetra.simplices[tetra2])\n",
    "    if len(commonVertices) < 3 or not segment_intersects_triangle(points_PBC[list(commonVertices)], p1, p2):\n",
    "        midPoint = (p1 + p2) / 2\n",
    "        bisectionSearch(p1, midPoint)\n",
    "        bisectionSearch(midPoint, p2)\n",
    "\n",
    "for edge in list(subG.edges):\n",
    "    bisectionSearch(vor.vertices[edge[0]], vor.vertices[edge[1]])\n",
    "    t1 = int(tetra.find_simplex(vor.vertices[edge[0]]))\n",
    "    t2 = int(tetra.find_simplex(vor.vertices[edge[1]]))\n",
    "        \n",
    "states = list(states)\n",
    "states.sort()\n",
    "\n",
    "statePrimary = set() # id of the primary states\n",
    "for i in states:\n",
    "    statePrimary.add(indexPrimary[i])\n",
    "if -1 in statePrimary:\n",
    "    statePrimary.remove(-1)\n",
    "    \n",
    "statePrimary = list(statePrimary) # statePrimary[new id] = original id\n",
    "statePrimary.sort()\n",
    "nStates = len(statePrimary)\n",
    "print(\"Number of primary states = \",nStates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_bisector_intersection(A, B, C):\n",
    "    \"\"\"\n",
    "    AB cross AC bisector at X, make sure AB is the longest side\n",
    "    return X and AX distance\n",
    "    \"\"\"\n",
    "    AB = B - A\n",
    "    AC = C - A\n",
    "    \n",
    "    # Parameter t along AB for the intersection:\n",
    "    t = np.linalg.norm(AC)**2 / (2 * np.dot(AC, AB))\n",
    "    #print(np.linalg.norm(AB), np.linalg.norm(AC), np.linalg.norm(B-C))\n",
    "    \n",
    "    # Intersection point:\n",
    "    X = A + t * AB\n",
    "    # Distance from A to X:\n",
    "    d = np.linalg.norm(X - A)\n",
    "    return d, X\n",
    "\n",
    "def sphere_line_intersection_closer_to_B(A, B, C, r):\n",
    "    d = B - A\n",
    "    V = A - C\n",
    "    d_norm_sq = np.dot(d, d)\n",
    "    \n",
    "    discriminant = (np.dot(V, d))**2 - d_norm_sq*(np.dot(V, V) - r**2)\n",
    "    sqrt_disc = np.sqrt(discriminant)\n",
    "    t = (-np.dot(V, d) + sqrt_disc) / d_norm_sq\n",
    "    \n",
    "    X = A + t * d\n",
    "    distance = np.linalg.norm(X - A)\n",
    "    \n",
    "    return X, distance\n",
    "\n",
    "def computeExitArea(p1, p2, p3, r):\n",
    "    c = np.linalg.norm(p1-p2)\n",
    "    b = np.linalg.norm(p1-p3)\n",
    "    a = np.linalg.norm(p3-p2)\n",
    "\n",
    "    # make sure c is the longest\n",
    "    if a > b and a > c:\n",
    "        a, c = copy.deepcopy(c), copy.deepcopy(a)\n",
    "        p1, p3 = copy.deepcopy(p3), copy.deepcopy(p1)\n",
    "    if b > a and b > c:\n",
    "        b, c = copy.deepcopy(c), copy.deepcopy(b)\n",
    "        p2, p3 = copy.deepcopy(p3), copy.deepcopy(p2)\n",
    "    s = (a + b + c) / 2\n",
    "    areaTriangle = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    R = a*b*c/4/areaTriangle\n",
    "    if R <= r:\n",
    "        return 0\n",
    "    \n",
    "    # if obtuse triangle and two circles intersect outside the triangle\n",
    "    d_AC, X_AC = distance_to_bisector_intersection(p1, p2, p3)\n",
    "    d_BC, X_BC = distance_to_bisector_intersection(p2, p1, p3)\n",
    "    #print(d_AC, d_BC, r)\n",
    "    if r > d_AC and r > d_BC:\n",
    "        return 0.0\n",
    "    if r > d_AC or r > d_BC:\n",
    "        if d_BC < d_AC: # make sure the side close to A is covered instead of B.\n",
    "            a, b = b, a\n",
    "            p1, p2 = p2, p1\n",
    "            d_AC, d_BC = d_BC, d_AC\n",
    "            X_AC, X_BC = X_BC, X_AC\n",
    "            X, XA = sphere_line_intersection_closer_to_B(p1, p2, p3, r)\n",
    "            b = r\n",
    "            c = c - XA\n",
    "            s = (a + b + c) / 2\n",
    "            areaTriangle = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "            angleX = np.arccos(np.clip(np.dot(p3-X, p2-X) / b / c, -1, 1))\n",
    "            areaTriangle -= r*r/2 * (np.pi - angleX)\n",
    "            if a < 2*r:\n",
    "                areaTriangle += r*r*np.arccos(a / (2 * r)) - (a / 4) * np.sqrt(4 * r**2 - a**2)\n",
    "            return areaTriangle\n",
    "\n",
    "    dA = areaTriangle * 2.0 / a\n",
    "    dB = areaTriangle * 2.0 / b\n",
    "    dC = areaTriangle * 2.0 / c\n",
    "    areaTriangle -= np.pi * r * r / 2\n",
    "    # deal with overlaps\n",
    "    if a < 2*r:\n",
    "        areaTriangle += r*r*np.arccos(a / (2 * r)) - (a / 4) * np.sqrt(4 * r**2 - a**2)\n",
    "    if b < 2*r:\n",
    "        areaTriangle += r*r*np.arccos(b / (2 * r)) - (b / 4) * np.sqrt(4 * r**2 - b**2)\n",
    "    if c < 2*r:\n",
    "        areaTriangle += r*r*np.arccos(c / (2 * r)) - (c / 4) * np.sqrt(4 * r**2 - c**2)\n",
    "    # deal with truncation from the opsite side\n",
    "    if dA < r:\n",
    "        areaTriangle += r**2 * np.arccos(dA/r) - dA * np.sqrt(r**2 - dA**2)\n",
    "    if dB < r:\n",
    "        areaTriangle += r**2 * np.arccos(dB/r) - dB * np.sqrt(r**2 - dB**2)\n",
    "    if dC < r:\n",
    "        areaTriangle += r**2 * np.arccos(dC/r) - dC * np.sqrt(r**2 - dC**2)\n",
    "\n",
    "    return areaTriangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute volume of tetra\n",
    "def tetra_volume(vertices):\n",
    "    \"\"\"Exact tetra volume from 4x3 array.\"\"\"\n",
    "    v = np.asarray(vertices, float).reshape(4,3)\n",
    "    return abs(np.dot(v[1]-v[0], np.cross(v[2]-v[0], v[3]-v[0]))) / 6.0\n",
    "\n",
    "\n",
    "def sample_points_in_tetrahedron(vertices, n):\n",
    "    rng = np.random.default_rng()\n",
    "    w = rng.dirichlet(np.ones(4), size=n)        # (n,4)\n",
    "    v = np.asarray(vertices, float).reshape(4,3) # (4,3)\n",
    "    return w @ v\n",
    "\n",
    "def cavityVolume(vertices, r, nTrails=int(1e9)):\n",
    "    v = np.asarray(vertices, float).reshape(4,3)\n",
    "    V0 = tetra_volume(v)\n",
    "\n",
    "    pts = sample_points_in_tetrahedron(v, nTrails)             # (n,3)\n",
    "    d2 = ((pts[:,None,:] - v[None,:,:])**2).sum(axis=2)         # (n,4)\n",
    "    covered = (d2 <= (r*r)).any(axis=1)                         # (n,)\n",
    "    p_uncovered = 1.0 - covered.mean()\n",
    "\n",
    "    est = V0 * p_uncovered\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitionPrimary = set(statePrimary)\n",
    "newStates = list(transitionPrimary)[:]\n",
    "G = nx.Graph()\n",
    "while len(newStates) > 0:\n",
    "    newState = newStates.pop()\n",
    "    for neighbor in tetra.neighbors[newState]:\n",
    "        vCommon = list(set(tetra.simplices[newState]) & set(tetra.simplices[neighbor]))\n",
    "        exitArea = computeExitArea(points_PBC[vCommon[0]], points_PBC[vCommon[1]], points_PBC[vCommon[2]], r_cut)\n",
    "        if exitArea > 0.0 and cavityVolume(points_PBC[tetra.simplices[neighbor]], r_cut, int(1e6)) > 0.0:\n",
    "            if newState > indexPrimary[neighbor]:\n",
    "                G.add_edge(indexPrimary[neighbor], newState)\n",
    "            else:\n",
    "                G.add_edge(newState, indexPrimary[neighbor])\n",
    "            if indexPrimary[neighbor] not in transitionPrimary:\n",
    "                newStates.append(indexPrimary[neighbor])\n",
    "            transitionPrimary.add(newState)\n",
    "            transitionPrimary.add(indexPrimary[neighbor])\n",
    "            \n",
    "transitionPrimary = list(transitionPrimary)\n",
    "transitionPrimary.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters:  1\n"
     ]
    }
   ],
   "source": [
    "sccs = list(nx.connected_components(G))\n",
    "sccs = sorted(sccs, key=len, reverse = True)\n",
    "sccs = [list(comp) for comp in sccs]\n",
    "print(\"Number of clusters: \", len(sccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "idVol = dict()\n",
    "for cnt, i in enumerate(transitionPrimary):\n",
    "    idVol[i] = cavityVolume(points_PBC[tetra.simplices[i]], r_cut, int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute channel area between neighboring tetrahedra\n",
    "channelArea = dict()\n",
    "for _, i in enumerate(transitionPrimary):\n",
    "    for j in tetra.neighbors[i]:\n",
    "        if i<indexPrimary[j] and indexPrimary[j] in transitionPrimary:\n",
    "            vCommon = list(set(tetra.simplices[i]) & set(tetra.simplices[j]))\n",
    "            exitArea = computeExitArea(points_PBC[vCommon[0]], points_PBC[vCommon[1]], points_PBC[vCommon[2]], r_cut)\n",
    "            if exitArea > 0.0 and idVol[indexPrimary[j]] > 0.0:\n",
    "                channelArea[(i, indexPrimary[j])] = exitArea\n",
    "\n",
    "channelArea_df = pd.DataFrame(list(channelArea.keys()), columns=['i', 'j'])\n",
    "channelArea_df['area'] = channelArea.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing edges:  []\n",
      "missing edges:  [(10281, 74480), (55440, 88219), (7841, 10125)]\n"
     ]
    }
   ],
   "source": [
    "# Improved search: find all pairs (i, j) in channelArea_df that are not in G.edges()\n",
    "missing_edges = []\n",
    "edges_set = set(G.edges())\n",
    "for i, row in channelArea_df.iterrows():\n",
    "    e1, e2 = row['i'], row['j']\n",
    "    if (e1, e2) not in edges_set and (e2, e1) not in edges_set:\n",
    "        missing_edges.append((e1, e2))\n",
    "print(\"missing edges: \", missing_edges)\n",
    "\n",
    "missing_edges = []\n",
    "for edge in G.edges():\n",
    "    e1, e2 = edge\n",
    "    if e1 > e2:\n",
    "        e1, e2 = e2, e1\n",
    "    if len(channelArea_df[(channelArea_df['i'] == e1) & (channelArea_df['j'] == e2)]) == 0:\n",
    "        missing_edges.append((e1, e2))\n",
    "print(\"missing edges: \", missing_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_id = [i for i in range(numBeads * 27)]\n",
    "points_image_id = [i%numBeads for i in range(numBeads * 27)]\n",
    "points_PBC_df = pd.DataFrame({'id': points_id, 'image_id': points_image_id})\n",
    "\n",
    "points_PBC_df['tetra_id'] = [[] for _ in range(len(points_PBC_df))]\n",
    "for tid, simplex in enumerate(tetra.simplices):\n",
    "    for vid in simplex:\n",
    "        points_PBC_df.loc[vid, 'tetra_id'].append(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tetra_id = [i for i in range(len(tetra.simplices))]\n",
    "tetra_obstacles_id = [sorted(i) for i in tetra.simplices]\n",
    "\n",
    "tetra_df = pd.DataFrame({'id': tetra_id, 'obstacles_id': tetra_obstacles_id})\n",
    "\n",
    "\n",
    "tetra_df['x'] = comAll[:,0]\n",
    "tetra_df['y'] = comAll[:,1]\n",
    "tetra_df['z'] = comAll[:,2]\n",
    "\n",
    "tetra_df['is_prime'] = (tetra_df['x'] > 0) & (tetra_df['x'] < box_size) & (tetra_df['y'] > 0) & (tetra_df['y'] < box_size) & (tetra_df['z'] > 0) & (tetra_df['z'] < box_size)\n",
    "tetra_df['image_id'] = tetra_df['id'].apply(lambda x: indexPrimary[x])\n",
    "\n",
    "tetra_df['is_percolation'] = tetra_df['id'].apply(lambda x: x in transitionPrimary)\n",
    "tetra_df = tetra_df[tetra_df['is_percolation']]\n",
    "tetra_df['percolation_id'] = tetra_df['is_percolation'].cumsum()\n",
    "tetra_df.loc[~tetra_df['is_percolation'], 'percolation_id'] = -1\n",
    "tetra_df.loc[tetra_df['is_percolation'], 'percolation_id'] = tetra_df.loc[tetra_df['is_percolation'], 'percolation_id']-1\n",
    "tetra_df.loc[tetra_df['is_percolation'], 'volume'] = tetra_df.loc[tetra_df['is_percolation'], 'id'].apply(lambda x: idVol[x])\n",
    "tetra_df['vol_fraction'] = tetra_df['volume'] / sum(idVol.values())\n",
    "tetra_df['vol_fraction'] = tetra_df['vol_fraction'].fillna(0)\n",
    "tetra_df['vol_fraction_cum'] = tetra_df['vol_fraction'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate probe particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tetra_volume(a, b, c, d) -> float:\n",
    "    return abs(np.dot(a - d, np.cross(b - d, c - d))) / 6.0\n",
    "\n",
    "def point_in_tetra(v, p, tol: float = 1e-5) -> bool:\n",
    "    v = np.asarray(v, float).reshape(4, 3)\n",
    "    p = np.asarray(p, float).reshape(3)\n",
    "\n",
    "    V  = tetra_volume(v[0], v[1], v[2], v[3])\n",
    "    V1 = tetra_volume(p,    v[1], v[2], v[3])\n",
    "    V2 = tetra_volume(v[0], p,    v[2], v[3])\n",
    "    V3 = tetra_volume(v[0], v[1], p,    v[3])\n",
    "    V4 = tetra_volume(v[0], v[1], v[2], p)\n",
    "\n",
    "    return np.isclose(V1 + V2 + V3 + V4, V, atol=tol, rtol=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes_XYZ = []\n",
    "for i in range(numProbes):\n",
    "    ifOverlap = True\n",
    "    while ifOverlap:\n",
    "        ifOverlap = False\n",
    "        \n",
    "        rd = np.random.random()\n",
    "        ind = tetra_df.loc[tetra_df['vol_fraction_cum']>rd].iloc[0]['id']\n",
    "        vertices = np.array([points_PBC[i] for i in tetra_df.loc[ind, 'obstacles_id']])\n",
    "        probeTmp = sample_points_in_tetrahedron(vertices, 1)[0]\n",
    "        \n",
    "        if not point_in_tetra(vertices, probeTmp):\n",
    "            raise SystemExit(\"Probe particle is not in the tetrahedron\")\n",
    "            \n",
    "        for obstacle in points_PBC:\n",
    "            if np.linalg.norm(probeTmp - obstacle) <= r_cut:\n",
    "                ifOverlap = True\n",
    "                break\n",
    "\n",
    "    probes_XYZ.append(probeTmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthUnit = r_cut*0.5\n",
    "\n",
    "tetra_df['x'] = tetra_df['x']/lengthUnit\n",
    "tetra_df['y'] = tetra_df['y']/lengthUnit\n",
    "tetra_df['z'] = tetra_df['z']/lengthUnit\n",
    "\n",
    "tetra_df['volume'] = tetra_df['volume']/lengthUnit**3\n",
    "\n",
    "channelArea_df['area'] = channelArea_df['area'] / lengthUnit**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# save configurations\n",
    "outfile = filepath + '.pos'\n",
    "with open(outfile, 'w') as output_fileID:\n",
    "    output_fileID.write(f'{len(points) + len(probes_XYZ)}\\n')\n",
    "    output_fileID.write(f'Lattice=\"{box_size/lengthUnit} 0 0 0 {box_size/lengthUnit} 0 0 0 {box_size/lengthUnit}\" Properties=species:S:1:pos:R:3:radius:R:1\\n')\n",
    "\n",
    "    for bid in range(len(points)):\n",
    "        output_fileID.write(f'{0} {points[bid][0]/lengthUnit} {points[bid][1]/lengthUnit} {points[bid][2]/lengthUnit} {2.0}\\n')\n",
    "    for probe in probes_XYZ:\n",
    "        output_fileID.write(f'{1} {probe[0]/lengthUnit} {probe[1]/lengthUnit} {probe[2]/lengthUnit} {0.0}\\n')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save obstacles info\n",
    "outfile = filepath + '_obstacles.csv'\n",
    "#points_PBC_df.to_csv(outfile, index = False, float_format='%.17f')\n",
    "\n",
    "outfile = filepath + '_tetra.txt'\n",
    "\n",
    "tetra_df[tetra_df['is_prime']].to_csv(outfile, sep=',', index = False, float_format='%.18f')\n",
    "\n",
    "# save channel area and cavity volume\n",
    "outfile = filepath + '_area.txt'\n",
    "channelArea_df.to_csv(outfile, index=False, float_format='%.18f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
